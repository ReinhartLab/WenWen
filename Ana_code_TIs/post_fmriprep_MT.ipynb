{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74307f0a-cd41-4b64-99d3-26d4b385595f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting,image\n",
    "from nilearn.image import load_img, math_img\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "from scipy.stats import norm\n",
    "from bids import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e178ee2-6cb1-4ceb-87fa-19211c82b11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIDS Layout: .../viscog01/Wen/IBL_TI_fMRI/BIDS | Subjects: 3 | Sessions: 3 | Runs: 18\n"
     ]
    }
   ],
   "source": [
    "# define directory\n",
    "myDir = {\n",
    "    'bids': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/',\n",
    "    'prep': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/',\n",
    "    'fs': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/freesurfer/',\n",
    "    'fig': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Figs/',\n",
    "    'res': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Results/',\n",
    "    'ana': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Ana_code/',\n",
    "    'templates': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Ana_code/templates/',\n",
    "}\n",
    "os.environ['SUBJECTS_DIR'] = '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/freesurfer'\n",
    "\n",
    "layout = BIDSLayout(myDir['bids'])\n",
    "print(layout)\n",
    "all_subs = layout.get_subjects()\n",
    "# all_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5c4dd7-e44c-4356-9c44-83d5254ace09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj = open(join(myDir['bids'],'subj_single.txt'), 'r').readlines()\n",
    "subj=subj[0].strip()\n",
    "# subj = 'S02'\n",
    "subj_name= [element for element in all_subs if subj in element] # full name of this subj\n",
    "subj_name = subj_name[0]\n",
    "subj_dir = join(myDir['prep'], f'sub-{subj_name}',f'ses-{subj_name}')\n",
    "# print(subj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774651b1-023e-4e3f-b1f1-a68ef704bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_task = 'MT'\n",
    "# inspace = 'T1w' # perform glm in individual space\n",
    "inspace = 'MNI152NLin2009cAsym' # perform glm in ï¼Ÿ space\n",
    "\n",
    "img_name = glob.glob(join(subj_dir,'func', f'*{func_task}*{inspace}*desc-preproc_bold.nii.gz'))\n",
    "# print(img_name)\n",
    "fmri_img = load_img(img_name[0])\n",
    "tr = fmri_img.header.get_zooms()[3]\n",
    "vox_size = fmri_img.header.get_zooms()[0]\n",
    "# print(tr,vox_size,fmri_img.shape) # dummy scans are included in data and event onset timing\n",
    "\n",
    "from nilearn.image import mean_img\n",
    "mean_img = mean_img(fmri_img)\n",
    "\n",
    "img_name = glob.glob(join(subj_dir,'func', f'*{func_task}*{inspace}*desc-brain_mask.nii.gz'))\n",
    "fmri_mask = load_img(img_name[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9429fc30-9322-4b2d-bde5-0e9b324b2255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read events\n",
    "events = pd.read_csv(join(myDir['ana'],'timing',func_task,f'{subj}.csv'))\n",
    "# motion parameters jointly observed with fMRI acquisitions\n",
    "\n",
    "conf_file = glob.glob(join(subj_dir,'func', f'*{func_task}*desc-confounds_timeseries.tsv'))\n",
    "# print(conf_file)\n",
    "add_reg_names = ['white_matter','global_signal','framewise_displacement','trans_x', 'trans_y', 'trans_z','rot_x', 'rot_y', 'rot_z']  # Replace with your actual column names\n",
    "# add_reg_names = ['framewise_displacement','trans_x', 'trans_y', 'trans_z','rot_x', 'rot_y', 'rot_z']  # Replace with your actual column names\n",
    "confounds_glm = pd.read_csv(conf_file[0], delimiter='\\t',usecols=add_reg_names)\n",
    "confounds_glm = confounds_glm.fillna(0) # replace nan with zeros, mostly for the first element in FD    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538c97b7-5ab5-4c0e-9457-fa667b77ff3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/viscog01/venvs/wen_env/bin/python/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:166: UserWarning: The following unexpected columns in events data will be ignored: weight\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hrf_model = 'spm + derivative + dispersion'\n",
    "# hrf_model = 'spm'\n",
    "# signal_scaling: False, int or (int, int), default=0\n",
    "#     If not False, fMRI signals are scaled to the mean value of scaling_axis given, which can be 0, 1 or (0, 1). 0 refers to mean scaling each voxel with respect to time, 1 refers to mean scaling each time point with respect to all voxels & (0, 1) refers to scaling with respect to voxels and time, which is known as grand mean scaling. Incompatible with standardize (standardize=False is enforced when signal_scaling is not False).\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=float(tr),slice_time_ref=0.5,mask_img=fmri_mask,\n",
    "                          noise_model='ar1',hrf_model=hrf_model,\n",
    "                          drift_model='cosine',\n",
    "                          high_pass=1./100,smoothing_fwhm=2*vox_size,\n",
    "                          signal_scaling=(0,1), \n",
    "                          minimize_memory=False,n_jobs=-2)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, events,confounds_glm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443619de-4aa3-43e3-a890-52e3ee771a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define contrast\n",
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "contrasts = {\n",
    "    'Motion_Static': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                         np.where(design_matrix.columns.str.contains('Motion'), 1,\n",
    "                              np.where(design_matrix.columns.str.contains('Static'), -1,0))),\n",
    "    'Motion_Static_loc1': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Motion_loc1'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Static_loc1'), -1,0))),\n",
    "    'Motion_Static_loc2': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Motion_loc2'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Static_loc2'), -1,0))),\n",
    "    'Motion_Static_loc3': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Motion_loc3'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Static_loc3'), -1,0))),\n",
    "}\n",
    "\n",
    "# from nilearn.plotting import plot_contrast_matrix\n",
    "# for key, values in contrasts.items():\n",
    "#     plot_contrast_matrix(values, design_matrix=design_matrix)\n",
    "#     plt.suptitle(key)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5de3423-bea1-499c-acc7-04607cc6ce4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate mask based on fs labels\n",
    "fs_label_dir = join(myDir['fs'],'fsaverage','label')\n",
    "pj = {'start':0, 'stop':1, 'delta':0.1, 'type':'frac'}\n",
    "# In order to have a ROI that fully covers gray matter, you can try proj frac 0 1 0.01 switch. The values mean a starting point (0=white matter surface), an ending point (1=pial surface), and a step between two. \n",
    "\n",
    "hemiStr = ['lh', 'rh']\n",
    "\n",
    "orig_path = join(myDir['fs'],'fsaverage', 'mri', 'orig.mgz')\n",
    "contrast_name = list(contrasts.keys())[0]\n",
    "# because I used MNI-registered data, it doesn't matter which subject is used as template here.\n",
    "temp_path = join(myDir['res'],'S04_MT_Motion_Static_fpr_thresh0.01_clusterVoxN3.nii.gz') # into functional space\n",
    "# temp_path = join(myDir['res'],f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz') # into functional space\n",
    "\n",
    "import subprocess\n",
    "for hemi in hemiStr:\n",
    "    label_path = join(fs_label_dir, f'{hemi}.MT_exvivo.label')\n",
    "    output_path = join(fs_label_dir, f'space-func-{hemi}_MT.nii.gz')\n",
    "    if not os.path.exists(output_path):        \n",
    "        command = [\n",
    "            'mri_label2vol',\n",
    "            '--subject', 'fsaverage',\n",
    "            '--label', label_path,\n",
    "            '--fillthresh', '0.3',\n",
    "            '--proj', pj['type'], str(pj['start']), str(pj['stop']), str(pj['delta']),\n",
    "            '--temp', temp_path,\n",
    "            '--regheader', orig_path,\n",
    "            '--hemi', hemi,\n",
    "            '--o', output_path\n",
    "        ]\n",
    "        subprocess.run(command)\n",
    "\n",
    "# for hemi in hemiStr:\n",
    "#     output_path = join(fs_label_dir, f'{hemi}_MT.nii.gz')\n",
    "#     print(output_path)\n",
    "#     image = load_img(output_path)\n",
    "#     # Plot the images on the same figure\n",
    "#     plotting.plot_stat_map(image, bg_img=orig_path,title=f'FreeSurfer Label: MT {hemi.capitalize()}', cut_coords=None, display_mode='ortho', colorbar=True)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b5403c-e9b9-484a-b29e-ed9d27f61139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python package you are importing, AtlasReader, is licensed under the\n",
      "BSD-3 license; however, the atlases it uses are separately licensed under more\n",
      "restrictive frameworks.\n",
      "By using AtlasReader, you agree to abide by the license terms of the\n",
      "individual atlases. Information on these terms can be found online at:\n",
      "https://github.com/miykael/atlasreader/tree/master/atlasreader/data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pip install atlasreader\n",
    "\n",
    "from nilearn.plotting import plot_stat_map,plot_img, show\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "from nilearn.reporting import get_clusters_table, make_glm_report\n",
    "from atlasreader import create_output\n",
    "from pathlib import Path\n",
    "\n",
    "def run_glm_analysis(thresh_p, cluster_vox_num, hc,isow):\n",
    "    z_maps = {}\n",
    "    fig, axes = plt.subplots(len(contrasts), 1, figsize=(15, 8))\n",
    "\n",
    "    for i, (contrast_name, contrast_values) in enumerate(contrasts.items(), 1):\n",
    "        out_dir = Path(myDir['fig']) / subj / func_task\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # delete previous atlasreader output if any\n",
    "        files_to_delete = glob.glob(join(out_dir,'atlasreader*'))\n",
    "        for file_path in files_to_delete:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                \n",
    "        res_filename = join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz')\n",
    "        pic_name = join(myDir['fig'], f'{subj}_{func_task}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png')\n",
    "        if os.path.exists(res_filename) and os.path.exists(pic_name) and isow == 0:\n",
    "            return\n",
    "            \n",
    "        tmp_zmap = fmri_glm.compute_contrast(contrast_values, output_type='z_score')\n",
    "        z_maps[contrast_name] = tmp_zmap\n",
    "\n",
    "        thresholded_map, threshold = threshold_stats_img(z_maps[contrast_name], mask_img=fmri_mask, alpha=thresh_p, height_control=hc)\n",
    "        thresholded_map.to_filename(res_filename)\n",
    "\n",
    "        # get location of significant clusters in an Atlas\n",
    "        create_output(thresholded_map, cluster_extent=cluster_vox_num, voxel_thresh=norm.ppf(1 - thresh_p / 2),\n",
    "                      direction='pos', outdir=out_dir)\n",
    "\n",
    "        # rename output\n",
    "        old_filepath = join(out_dir,'atlasreader_clusters.csv')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(out_dir,f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader_clusters.csv')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "        old_filepath = join(out_dir,'atlasreader_peaks.csv')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(out_dir,f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader_peaks.csv')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "        old_filepath = join(out_dir,'atlasreader.png')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(myDir['fig'],f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader.png')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "\n",
    "        out_directory = Path(myDir['fig']) / 'atlasreader'\n",
    "        out_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Use pathlib to list and rename files\n",
    "        old_dir = Path(out_dir)\n",
    "        png_files = old_dir.glob('atlasreader_cluster*.png')\n",
    "        if any(png_files):\n",
    "            _ = [file.rename(out_directory / f\"{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_{file.name}\") for file in png_files]\n",
    "\n",
    "        # export report of first-level glm\n",
    "        report = make_glm_report(fmri_glm, contrasts=contrasts[contrast_name], bg_img=mean_img, threshold=threshold,\n",
    "                                 alpha=thresh_p, height_control=hc)\n",
    "        report.save_as_html(join(myDir['fig'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_GLM_report.html'))\n",
    "\n",
    "        # # cluster\n",
    "        # table = get_clusters_table(z_maps[contrast_name], stat_threshold=threshold, cluster_threshold=cluster_vox_num)\n",
    "        # table.to_csv(join(myDir['fig'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_cluster_table.csv'))\n",
    "\n",
    "        plot_stat_map(z_maps[contrast_name], bg_img=mean_img, threshold=threshold,\n",
    "                      display_mode='z', cut_coords=3, black_bg=True,\n",
    "                      title=f\"{contrast_name}, fdr p<{thresh_p:.3f}, threshold={threshold:.3f}\", axes=axes[i - 1])\n",
    "\n",
    "    plt.savefig(pic_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b00782-18fd-45cf-b763-885e53f73cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "\n",
    "def plot_glm_and_mask(thresh_p, cluster_vox_num, hc,isow):\n",
    "    \n",
    "    contrast_name = 'Motion_Static'\n",
    "    res_filename = join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_masked.nii.gz')\n",
    "    pic_name = join(myDir['fig'], f'{subj}_{func_task}_glm_and_mask_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png')\n",
    "\n",
    "    if os.path.exists(res_filename) and os.path.exists(pic_name) and isow == 0:\n",
    "        return\n",
    "        \n",
    "    MT_l = join(fs_label_dir, f'space-func-lh_MT.nii.gz')\n",
    "    MT_r = join(fs_label_dir, f'space-func-rh_MT.nii.gz')\n",
    "    combined_mask_img = image.math_img('(mask1_img > 0) | (mask2_img > 0)', mask1_img=MT_l, mask2_img=MT_r)\n",
    "\n",
    "    # Load GLM Result of all locations, set Image > Scrambled\n",
    "    glm_result = load_img(join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz'))\n",
    "    glm_result = image.math_img('np.clip(img, 0, None)', img=glm_result)\n",
    "\n",
    "    # Apply mt mask to the GLM result\n",
    "    masked_glm_result = image.math_img('glm_result * mt_mask', glm_result=glm_result, mt_mask=combined_mask_img)\n",
    "    masked_glm_result.to_filename(res_filename)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "    plotting.plot_roi(combined_mask_img, title='MT Mask', axes=axes[0])\n",
    "    plotting.plot_stat_map(glm_result, title='GLM Result', axes=axes[1])\n",
    "    plotting.plot_stat_map(masked_glm_result, title='Masked GLM Result', cut_coords=None, display_mode='ortho', colorbar=True, axes=axes[2])\n",
    "\n",
    "    plt.savefig(pic_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77294f32-c194-4947-98ea-0b4d03d2ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import datasets, surface, plotting, image\n",
    "from os.path import join\n",
    "from scipy.stats import norm\n",
    "\n",
    "def plot_surf_localizer1st(thresh_p_values, cluster_vox_num_values, hc_values, myDir, subj, func_task,contrast_name):\n",
    "    # Load fsaverage surfaces\n",
    "    fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage7')\n",
    "\n",
    "    # Load curvature data and compute sign\n",
    "    curv_right = surface.load_surf_data(fsaverage.curv_right)\n",
    "    curv_right_sign = np.sign(curv_right)\n",
    "\n",
    "    curv_left = surface.load_surf_data(fsaverage.curv_left)\n",
    "    curv_left_sign = np.sign(curv_left)\n",
    "\n",
    "    viewAng = ['lateral', 'posterior']\n",
    "    col = len(viewAng)\n",
    "\n",
    "    for thresh_p in thresh_p_values:\n",
    "        for cluster_vox_num in cluster_vox_num_values:\n",
    "            for hc in hc_values:\n",
    "                glm_dir = join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz')\n",
    "\n",
    "                if not os.path.exists(glm_dir):\n",
    "                    return \n",
    "                glm_result = image.load_img(glm_dir)\n",
    "                glm_result = image.math_img('np.clip(img, 0, None)', img=glm_result)\n",
    "\n",
    "                # Convert glm_result to surface texture\n",
    "                texture = surface.vol_to_surf(glm_result, fsaverage.pial_right)\n",
    "                textureL = surface.vol_to_surf(glm_result, fsaverage.pial_left)\n",
    "\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "                for c, view in enumerate(viewAng, 1):\n",
    "                    ax = fig.add_subplot(col, 2, 2*c-1, projection='3d')\n",
    "                    im = plotting.plot_surf_stat_map(\n",
    "                        fsaverage.infl_left, textureL, hemi='left',\n",
    "                        colorbar=True, vmax=5, threshold=norm.ppf(1-thresh_p/2), bg_map=curv_left, view=view, axes=ax\n",
    "                    )\n",
    "\n",
    "                    ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "\n",
    "                    ax = fig.add_subplot(col, 2, c*2, projection='3d')\n",
    "                    plotting.plot_surf_stat_map(\n",
    "                        fsaverage.infl_right, texture, hemi='right',\n",
    "                        colorbar=True, vmax=5, threshold=norm.ppf(1-thresh_p/2), bg_map=curv_right, view=view, axes=ax\n",
    "                    )\n",
    "                    ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "\n",
    "                plt.savefig(join(myDir['fig'], f'{subj}_{func_task}_surf_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53a08f-8d28-4d64-83df-d8eac4899124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/3755277.1.virtualgl/ipykernel_1368821/3501073136.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(8, 8))\n"
     ]
    }
   ],
   "source": [
    "thresh_p_values = [0.05,0.01, 0.005, 0.001]\n",
    "cluster_vox_num_values = [3, 5, 8, 10]\n",
    "hc_values = ['fpr', 'fdr']\n",
    "\n",
    "# thresh_p_values = [0.01]\n",
    "# cluster_vox_num_values = [3]\n",
    "# hc_values = ['fpr']\n",
    "\n",
    "isow = 0 # 1=overwrite,0= not\n",
    "contrast_name = 'Motion_Static' \n",
    "\n",
    "for thresh_p in thresh_p_values:\n",
    "    for cluster_vox_num in cluster_vox_num_values:\n",
    "        for hc in hc_values:\n",
    "            # run_glm_analysis(thresh_p, cluster_vox_num, hc,isow)\n",
    "            # plot_glm_and_mask(thresh_p, cluster_vox_num, hc,isow)\n",
    "            plot_surf_localizer1st(thresh_p_values, cluster_vox_num_values, hc_values, myDir, subj, func_task,contrast_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b63a6-a2be-4aff-b45a-b237a2408ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nilearn import datasets, surface\n",
    "# from nilearn import plotting\n",
    "# from nilearn.datasets import fetch_surf_fsaverage\n",
    "\n",
    "# # Load fsaverage surfaces\n",
    "# fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage7')\n",
    "\n",
    "# # # Load curvature data and compute sign\n",
    "# curv_right = surface.load_surf_data(fsaverage.curv_right)\n",
    "# curv_right_sign = np.sign(curv_right)\n",
    "\n",
    "# curv_left = surface.load_surf_data(fsaverage.curv_left)\n",
    "# curv_left_sign = np.sign(curv_left)\n",
    "\n",
    "# viewAng = ['lateral', 'posterior']\n",
    "# col = len(viewAng)\n",
    "# for thresh_p in thresh_p_values:\n",
    "#     for cluster_vox_num in cluster_vox_num_values:\n",
    "#         for hc in hc_values:\n",
    "\n",
    "#             contrast_name = 'Motion_Static' \n",
    "#             glm_result = load_img(join(myDir['res'],f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz'))\n",
    "#             glm_result = image.math_img('np.clip(img, 0, None)', img=glm_result)\n",
    "\n",
    "#             # Convert glm_result to surface texture\n",
    "#             texture = surface.vol_to_surf(glm_result, fsaverage.pial_right)\n",
    "#             textureL = surface.vol_to_surf(glm_result, fsaverage.pial_left)\n",
    "\n",
    "#             fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "#             for c, view in enumerate(viewAng, 1):\n",
    "#                 ax = fig.add_subplot(col,2, 2*c-1, projection='3d')\n",
    "#                 im = plotting.plot_surf_stat_map(\n",
    "#                     fsaverage.infl_left, textureL, hemi='left',\n",
    "#                     colorbar=True,vmax=5,threshold=norm.ppf(1-thresh_p/2), bg_map=curv_left, view=view, axes=ax\n",
    "#                 )\n",
    "            \n",
    "#                 ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "                \n",
    "#                 ax = fig.add_subplot(col,2, c*2, projection='3d')\n",
    "#                 plotting.plot_surf_stat_map(\n",
    "#                     fsaverage.infl_right, texture, hemi='right',\n",
    "#                     colorbar=True, vmax=5,threshold=norm.ppf(1-thresh_p/2), bg_map=curv_right, view=view, axes=ax\n",
    "#                 )\n",
    "#                 ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "                \n",
    "#             plt.savefig(join(myDir['fig'],f'{subj}_{func_task}_surf_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png'))\n",
    "#                 # plt.savefig(join(myDir['fig'],f'{subj}_{func_task}_surf_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png'),dpi=600)\n",
    "\n",
    "#             # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
