{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfee1a05-beff-4c16-91f0-105c7d38842c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.image import load_img, math_img\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "from scipy.stats import norm\n",
    "from bids import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56f053b-7153-4329-9f1e-6617ebfbf11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIDS Layout: .../viscog01/Wen/IBL_TI_fMRI/BIDS | Subjects: 3 | Sessions: 3 | Runs: 18\n"
     ]
    }
   ],
   "source": [
    "# define directory\n",
    "myDir = {\n",
    "    'bids': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/',\n",
    "    'prep': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/',\n",
    "    'fs': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/freesurfer/',\n",
    "    'fig': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Figs/',\n",
    "    'res': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Results/',\n",
    "    'ana': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Ana_code/',\n",
    "    'templates': '/projectnb2/viscog01/Wen/IBL_TI_fMRI/Ana_code/templates/',\n",
    "}\n",
    "os.environ['SUBJECTS_DIR'] = '/projectnb2/viscog01/Wen/IBL_TI_fMRI/BIDS/derivatives/freesurfer'\n",
    "\n",
    "layout = BIDSLayout(myDir['bids'])\n",
    "print(layout)\n",
    "all_subs = layout.get_subjects()\n",
    "# all_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5c4dd7-e44c-4356-9c44-83d5254ace09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "subj = open(join(myDir['bids'],'subj_single.txt'), 'r').readlines()\n",
    "subj=subj[0].strip()\n",
    "\n",
    "# subj = 'S02'\n",
    "subj_name= [element for element in all_subs if subj in element] # full name of this subj\n",
    "# print(subj_name)\n",
    "subj_name = subj_name[0]\n",
    "subj_dir = join(myDir['prep'], f'sub-{subj_name}',f'ses-{subj_name}')\n",
    "# print(subj_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774651b1-023e-4e3f-b1f1-a68ef704bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_task = 'OBA'\n",
    "# inspace = 'T1w' # perform glm in individual space\n",
    "inspace = 'MNI152NLin2009cAsym' # perform glm in ï¼Ÿ space\n",
    "\n",
    "img_name = glob.glob(join(subj_dir,'func', f'*{func_task}*{inspace}*desc-preproc_bold.nii.gz'))\n",
    "# print(img_name)\n",
    "fmri_img = load_img(img_name[0])\n",
    "tr = fmri_img.header.get_zooms()[3]\n",
    "vox_size = fmri_img.header.get_zooms()[0]\n",
    "# print(tr)\n",
    "\n",
    "from nilearn.image import mean_img\n",
    "mean_img = mean_img(fmri_img)\n",
    "\n",
    "img_name = glob.glob(join(subj_dir,'func', f'*{func_task}*{inspace}*desc-brain_mask.nii.gz'))\n",
    "fmri_mask = load_img(img_name[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9429fc30-9322-4b2d-bde5-0e9b324b2255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read events\n",
    "events = pd.read_csv(join(myDir['ana'],'timing',func_task,f'{subj}.csv'))\n",
    "# print(events)\n",
    "\n",
    "# motion parameters jointly observed with fMRI acquisitions\n",
    "\n",
    "conf_file = glob.glob(join(subj_dir,'func', f'*{func_task}*desc-confounds_timeseries.tsv'))\n",
    "# print(conf_file)\n",
    "add_reg_names = ['white_matter','global_signal','framewise_displacement','trans_x', 'trans_y', 'trans_z','rot_x', 'rot_y', 'rot_z']  # Replace with your actual column names\n",
    "# add_reg_names = ['framewise_displacement','trans_x', 'trans_y', 'trans_z','rot_x', 'rot_y', 'rot_z']  # Replace with your actual column names\n",
    "confounds_glm = pd.read_csv(conf_file[0], delimiter='\\t',usecols=add_reg_names)\n",
    "confounds_glm = confounds_glm.fillna(0) # replace nan with zeros, mostly for the first element in FD    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538c97b7-5ab5-4c0e-9457-fa667b77ff3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/viscog01/venvs/wen_env/bin/python/lib/python3.10/site-packages/nilearn/glm/first_level/experimental_paradigm.py:166: UserWarning: The following unexpected columns in events data will be ignored: weight\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hrf_model = 'spm + derivative + dispersion'\n",
    "# hrf_model = 'spm'\n",
    "# signal_scaling: False, int or (int, int), default=0\n",
    "#     If not False, fMRI signals are scaled to the mean value of scaling_axis given, which can be 0, 1 or (0, 1). 0 refers to mean scaling each voxel with respect to time, 1 refers to mean scaling each time point with respect to all voxels & (0, 1) refers to scaling with respect to voxels and time, which is known as grand mean scaling. Incompatible with standardize (standardize=False is enforced when signal_scaling is not False).\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=float(tr),slice_time_ref=0.5,mask_img=fmri_mask,\n",
    "                          noise_model='ar1',hrf_model=hrf_model,\n",
    "                          drift_model='cosine',\n",
    "                          high_pass=1./100,smoothing_fwhm=2*vox_size,\n",
    "                          signal_scaling=(0,1), \n",
    "                          minimize_memory=False,n_jobs=-2)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, events,confounds_glm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443619de-4aa3-43e3-a890-52e3ee771a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define contrast\n",
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "contrasts = {\n",
    "    'Image_Scramble': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                         np.where(design_matrix.columns.str.contains('Image'), 1,\n",
    "                              np.where(design_matrix.columns.str.contains('Scrambled'), -1,0))),\n",
    "    'Image_Scramble_loc1': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Image_loc1'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Scrambled_loc1'), -1,0))),\n",
    "    'Image_Scramble_loc2': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Image_loc2'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Scrambled_loc2'), -1,0))),\n",
    "    'Image_Scramble_loc3': np.where(design_matrix.columns.str.contains('derivative|dispersion'),0,\n",
    "                             np.where(design_matrix.columns.str.contains('Image_loc3'), 1,\n",
    "                                  np.where(design_matrix.columns.str.contains('Scrambled_loc3'), -1,0))),\n",
    "}\n",
    "\n",
    "# from nilearn.plotting import plot_contrast_matrix\n",
    "\n",
    "# for key, values in contrasts.items():\n",
    "#     plot_contrast_matrix(values, design_matrix=design_matrix)\n",
    "#     plt.suptitle(key)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3841bc6c-8d2d-483d-9e80-55764fd5f305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# define masks\n",
    "\n",
    "# using OBA template from Nancy Kanwisher's GSS CVS registration\n",
    "# https://web.mit.edu/bcs/nklab/GSS.shtml\n",
    "from nilearn.image import index_img\n",
    "img_name = join(myDir['templates'],'cvs_object_parcels', 'fROIs-fwhm_5-0.0001.nii')\n",
    "oba_gss_atlas = load_img(img_name)\n",
    "# print(oba_gss_atlas.shape)\n",
    "\n",
    "# Squeeze the 4D image to 3D\n",
    "oba_gss_atlas = index_img(oba_gss_atlas, 0)\n",
    "# print(oba_gss_atlas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78843fd-f819-40d7-93f3-38603952d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install atlasreader\n",
    "\n",
    "from nilearn.plotting import plot_stat_map,plot_img, show\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "from nilearn.reporting import get_clusters_table, make_glm_report\n",
    "from atlasreader import create_output\n",
    "from pathlib import Path\n",
    "\n",
    "def run_glm_analysis(thresh_p, cluster_vox_num, hc,isow):\n",
    "    z_maps = {}\n",
    "    fig, axes = plt.subplots(len(contrasts), 1, figsize=(15, 8))\n",
    "\n",
    "    for i, (contrast_name, contrast_values) in enumerate(contrasts.items(), 1):\n",
    "        out_dir = Path(myDir['fig']) / subj / func_task \n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # delete previous atlasreader output if any\n",
    "        files_to_delete = glob.glob(join(out_dir,'atlasreader*'))\n",
    "        for file_path in files_to_delete:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                \n",
    "        res_filename = join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz')\n",
    "        pic_name = join(myDir['fig'], f'{subj}_{func_task}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png')\n",
    "        if os.path.exists(res_filename) and os.path.exists(pic_name) and isow == 0:\n",
    "            return\n",
    "            \n",
    "        tmp_zmap = fmri_glm.compute_contrast(contrast_values, output_type='z_score')\n",
    "        z_maps[contrast_name] = tmp_zmap\n",
    "\n",
    "        thresholded_map, threshold = threshold_stats_img(z_maps[contrast_name], mask_img=fmri_mask, alpha=thresh_p, height_control=hc)\n",
    "        thresholded_map.to_filename(res_filename)\n",
    "\n",
    "        # get location of significant clusters in an Atlas\n",
    "        create_output(thresholded_map, cluster_extent=cluster_vox_num, voxel_thresh=norm.ppf(1 - thresh_p / 2),\n",
    "                      direction='pos', outdir=out_dir)\n",
    "\n",
    "        # rename output\n",
    "        old_filepath = join(out_dir,'atlasreader_clusters.csv')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(out_dir,f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader_clusters.csv')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "        old_filepath = join(out_dir,'atlasreader_peaks.csv')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(out_dir,f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader_peaks.csv')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "        old_filepath = join(out_dir, 'atlasreader.png')\n",
    "        if os.path.exists(old_filepath):\n",
    "            new_filepath = join(myDir['fig'],f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_atlasreader.png')\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "\n",
    "        out_directory = Path(myDir['fig']) / 'atlasreader'\n",
    "        out_directory.mkdir(exist_ok=True)\n",
    "\n",
    "        # Use pathlib to list and rename files\n",
    "        old_dir = Path(out_dir)\n",
    "        png_files = old_dir.glob('atlasreader_cluster*.png')\n",
    "        if any(png_files):\n",
    "            _ = [file.rename(out_directory / f\"{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_{file.name}\") for file in png_files]\n",
    "\n",
    "        # export report of first-level glm\n",
    "        report = make_glm_report(fmri_glm, contrasts=contrasts[contrast_name], bg_img=mean_img, threshold=threshold,\n",
    "                                 alpha=thresh_p, height_control=hc)\n",
    "        report.save_as_html(join(myDir['fig'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_GLM_report.html'))\n",
    "\n",
    "        # # cluster\n",
    "        # table = get_clusters_table(z_maps[contrast_name], stat_threshold=threshold, cluster_threshold=cluster_vox_num)\n",
    "        # table.to_csv(join(myDir['fig'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_cluster_table.csv'))\n",
    "\n",
    "        plot_stat_map(z_maps[contrast_name], bg_img=mean_img, threshold=threshold,\n",
    "                      display_mode='z', cut_coords=3, black_bg=True,\n",
    "                      title=f\"{contrast_name}, fdr p<{thresh_p:.3f}, threshold={threshold:.3f}\", axes=axes[i - 1])\n",
    "\n",
    "    plt.savefig(pic_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04449ca7-2479-4b2b-a857-993f32ff18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_glm_and_mask(thresh_p, cluster_vox_num, hc,isow):  \n",
    "    \n",
    "    contrast_name = 'Image_Scramble' \n",
    "    res_filename = join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}_masked.nii.gz')\n",
    "    pic_name = join(myDir['fig'], f'{subj}_{func_task}_glm_and_mask_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png')\n",
    "\n",
    "    if os.path.exists(res_filename) and os.path.exists(pic_name) and isow == 0:\n",
    "        return\n",
    "        \n",
    "    # Load GLM Result of all locations, set Image > Scrambled\n",
    "    glm_result = load_img(join(myDir['res'], f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz'))\n",
    "    glm_result = image.math_img('np.clip(img, 0, None)', img=glm_result)\n",
    "        \n",
    "    # resample and binarize, mask and glm result are in MNI space, arbitary thresh of 1.96 considering value interpolate\n",
    "    oba_mask_resampled = image.resample_to_img(oba_gss_atlas, glm_result)\n",
    "    oba_mask_resampled = image.math_img('img > 1.96', img=oba_mask_resampled)# mask p<0.05\n",
    "\n",
    "    # Apply mask to the GLM result\n",
    "    masked_glm_result = image.math_img('glm_result * roi_mask', glm_result=glm_result, roi_mask=oba_mask_resampled)\n",
    "    masked_glm_result.to_filename(res_filename)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "    plotting.plot_roi(combined_mask_img, title='OBA Mask', axes=axes[0])\n",
    "    plotting.plot_stat_map(glm_result, title='GLM Result', axes=axes[1])\n",
    "    plotting.plot_stat_map(masked_glm_result, title='Masked GLM Result', cut_coords=None, display_mode='ortho', colorbar=True, axes=axes[2])\n",
    "\n",
    "    plt.savefig(pic_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33444c-70d1-4579-9b37-73bb65c32fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# thresh_p_values = [0.01, 0.005, 0.0001]\n",
    "# cluster_vox_num_values = [3, 5, 8, 10]\n",
    "# hc_values = ['fpr', 'fdr']\n",
    "\n",
    "thresh_p_values = [0.001]\n",
    "cluster_vox_num_values = [3]\n",
    "hc_values = ['fpr']\n",
    "isow = 1 # 1=overwrite,0= not\n",
    "for thresh_p in thresh_p_values:\n",
    "    for cluster_vox_num in cluster_vox_num_values:\n",
    "        for hc in hc_values:\n",
    "            run_glm_analysis(thresh_p, cluster_vox_num, hc,isow)\n",
    "            plot_glm_and_mask(thresh_p, cluster_vox_num, hc,isow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b14eed6-9fa4-4f19-844c-66f87dfb781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets, surface\n",
    "from nilearn import plotting\n",
    "from nilearn.datasets import fetch_surf_fsaverage\n",
    "\n",
    "# Load fsaverage surfaces\n",
    "fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage7')\n",
    "\n",
    "# # Load curvature data and compute sign\n",
    "curv_right = surface.load_surf_data(fsaverage.curv_right)\n",
    "curv_right_sign = np.sign(curv_right)\n",
    "\n",
    "curv_left = surface.load_surf_data(fsaverage.curv_left)\n",
    "curv_left_sign = np.sign(curv_left)\n",
    "\n",
    "viewAng = ['lateral', 'posterior']\n",
    "col = len(viewAng)\n",
    "for thresh_p in thresh_p_values:\n",
    "    for cluster_vox_num in cluster_vox_num_values:\n",
    "        for hc in hc_values:\n",
    "\n",
    "            contrast_name = 'Image_Scramble' \n",
    "            glm_result = load_img(join(myDir['res'],f'{subj}_{func_task}_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.nii.gz'))\n",
    "            glm_result = image.math_img('np.clip(img, 0, None)', img=glm_result)\n",
    "\n",
    "            # Convert glm_result to surface texture\n",
    "            texture = surface.vol_to_surf(glm_result, fsaverage.pial_right)\n",
    "            textureL = surface.vol_to_surf(glm_result, fsaverage.pial_left)\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "            for c, view in enumerate(viewAng, 1):\n",
    "                ax = fig.add_subplot(col,2, 2*c-1, projection='3d')\n",
    "                im = plotting.plot_surf_stat_map(\n",
    "                    fsaverage.infl_left, textureL, hemi='left',\n",
    "                    colorbar=True,vmax=5,threshold=norm.ppf(1-thresh_p/2), bg_map=curv_left, view=view, axes=ax\n",
    "                )\n",
    "            \n",
    "                ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "                \n",
    "                ax = fig.add_subplot(col,2, c*2, projection='3d')\n",
    "                plotting.plot_surf_stat_map(\n",
    "                    fsaverage.infl_right, texture, hemi='right',\n",
    "                    colorbar=True, vmax=5,threshold=norm.ppf(1-thresh_p/2), bg_map=curv_right, view=view, axes=ax\n",
    "                )\n",
    "                ax.set_title(f'{contrast_name} ({view.capitalize()})\\nUncorrected p<{thresh_p}')\n",
    "                \n",
    "            plt.savefig(join(myDir['fig'],f'{subj}_{func_task}_surf_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png'))\n",
    "                # plt.savefig(join(myDir['fig'],f'{subj}_{func_task}_surf_{contrast_name}_{hc}_thresh{thresh_p}_clusterVoxN{cluster_vox_num}.png'),dpi=600)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
